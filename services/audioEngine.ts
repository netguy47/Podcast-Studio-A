
import * as lamejs from 'lamejs';
import { PodcastSegment, UserTier } from '../types';

/**
 * Resumes AudioContext if it's suspended (browser policy).
 */
export async function ensureAudioContext(ctx: AudioContext) {
  if (ctx.state === 'suspended') {
    await ctx.resume();
  }
}

/**
 * Generates a small beep/audio sequence as a watermark for FREE users.
 */
export async function createWatermarkBuffer(ctx: AudioContext): Promise<AudioBuffer> {
  const duration = 1.5;
  const sampleRate = ctx.sampleRate;
  const buffer = ctx.createBuffer(1, sampleRate * duration, sampleRate);
  const data = buffer.getChannelData(0);
  
  for (let i = 0; i < data.length; i++) {
    // Simple fading sine wave sequence "Generated by AI" vibe
    const t = i / sampleRate;
    data[i] = Math.sin(2 * Math.PI * 440 * t) * Math.exp(-3 * t) * 0.1;
  }
  return buffer;
}

/**
 * Generates audio using a public Edge TTS Proxy (Free Tier).
 */
export async function generateBrowserSpeech(text: string, voiceName: string, ctx: AudioContext): Promise<AudioBuffer> {
  await ensureAudioContext(ctx);
  const proxyUrl = `https://edge-tts-proxy.vercel.app/api/tts?text=${encodeURIComponent(text)}&voice=${voiceName}`;
  
  try {
    const response = await fetch(proxyUrl);
    if (!response.ok) {
      const fallbackUrl = `https://api.suen.me/tts?text=${encodeURIComponent(text)}&voice=${voiceName}`;
      const fallbackResponse = await fetch(fallbackUrl);
      if (!fallbackResponse.ok) throw new Error("Edge TTS Proxy failed");
      const arrayBuffer = await fallbackResponse.arrayBuffer();
      return await ctx.decodeAudioData(arrayBuffer);
    }
    const arrayBuffer = await response.arrayBuffer();
    return await ctx.decodeAudioData(arrayBuffer);
  } catch (error) {
    console.error("Edge TTS Error:", error);
    throw new Error("Failed to generate Free Edge TTS audio. Please try again or switch to Pro.");
  }
}

/**
 * Decodes base64 PCM data into an AudioBuffer.
 */
export async function decodeGeminiAudio(
  base64: string,
  ctx: AudioContext
): Promise<AudioBuffer> {
  await ensureAudioContext(ctx);
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }

  const dataInt16 = new Int16Array(bytes.buffer);
  const frameCount = dataInt16.length;
  const buffer = ctx.createBuffer(1, frameCount, 24000); 

  const channelData = buffer.getChannelData(0);
  for (let i = 0; i < frameCount; i++) {
    channelData[i] = dataInt16[i] / 32768.0;
  }
  return buffer;
}

export function concatenateAudioBuffers(
  buffers: AudioBuffer[],
  ctx: AudioContext
): AudioBuffer {
  if (buffers.length === 0) return ctx.createBuffer(1, 1, 44100);
  
  // Use a consistent sample rate (e.g., the context's rate)
  const rate = buffers[0].sampleRate;
  const totalLength = buffers.reduce((acc, buf) => acc + buf.length, 0);
  const result = ctx.createBuffer(1, totalLength, rate);
  
  let offset = 0;
  for (const buf of buffers) {
    // If buffer rates differ, we would normally need to resample, 
    // but here we assume our sources are consistent or we use getChannelData directly.
    result.getChannelData(0).set(buf.getChannelData(0), offset);
    offset += buf.length;
  }
  return result;
}

export function generateSRT(segments: PodcastSegment[]): string {
  let srt = "";
  let counter = 1;

  const formatTime = (seconds: number) => {
    const h = Math.floor(seconds / 3600).toString().padStart(2, '0');
    const m = Math.floor((seconds % 3600) / 60).toString().padStart(2, '0');
    const s = Math.floor(seconds % 60).toString().padStart(2, '0');
    const ms = Math.floor((seconds % 1) * 1000).toString().padStart(3, '0');
    return `${h}:${m}:${s},${ms}`;
  };

  segments.forEach((seg) => {
    if (seg.startTime !== undefined && seg.duration !== undefined) {
      srt += `${counter}\n`;
      srt += `${formatTime(seg.startTime)} --> ${formatTime(seg.startTime + seg.duration)}\n`;
      srt += `${seg.speaker}: ${seg.text}\n\n`;
      counter++;
    }
  });

  return srt;
}

export function audioBufferToWav(buffer: AudioBuffer): Blob {
  const numOfChan = buffer.numberOfChannels;
  const length = buffer.length * numOfChan * 2 + 44;
  const bufferArray = new ArrayBuffer(length);
  const view = new DataView(bufferArray);
  const channels: Float32Array[] = [];
  let i: number;
  let sample: number;
  let pos = 0;

  const setUint16 = (data: number) => { view.setUint16(pos, data, true); pos += 2; };
  const setUint32 = (data: number) => { view.setUint32(pos, data, true); pos += 4; };

  setUint32(0x46464952); setUint32(length - 8); setUint32(0x45564157);
  setUint32(0x20746d66); setUint32(16); setUint16(1); setUint16(numOfChan);
  setUint32(buffer.sampleRate); setUint32(buffer.sampleRate * 2 * numOfChan);
  setUint16(numOfChan * 2); setUint16(16); setUint32(0x61746164);
  setUint32(length - pos - 4);

  for (i = 0; i < buffer.numberOfChannels; i++) {
    channels.push(buffer.getChannelData(i));
  }
  
  let sampleIndex = 0;
  while (pos < length) {
    for (i = 0; i < numOfChan; i++) {
      sample = Math.max(-1, Math.min(1, channels[i][sampleIndex]));
      sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0;
      view.setInt16(pos, sample, true);
      pos += 2;
    }
    sampleIndex++;
  }
  return new Blob([bufferArray], { type: "audio/wav" });
}

export function audioBufferToMp3(buffer: AudioBuffer): Blob {
  const channels = 1; 
  const sampleRate = buffer.sampleRate;
  const kbps = 128;
  const mp3encoder = new (lamejs as any).Mp3Encoder(channels, sampleRate, kbps);
  const mp3Data: Int8Array[] = [];

  const floatData = buffer.getChannelData(0);
  const sampleBlockSize = 1152;
  
  const samples = new Int16Array(floatData.length);
  for (let i = 0; i < floatData.length; i++) {
    samples[i] = floatData[i] < 0 ? floatData[i] * 32768 : floatData[i] * 32767;
  }

  for (let i = 0; i < samples.length; i += sampleBlockSize) {
    const sampleChunk = samples.subarray(i, i + sampleBlockSize);
    const mp3buf = mp3encoder.encodeBuffer(sampleChunk);
    if (mp3buf.length > 0) {
      mp3Data.push(mp3buf);
    }
  }

  const mp3last = mp3encoder.flush();
  if (mp3last.length > 0) {
    mp3Data.push(mp3last);
  }

  return new Blob(mp3Data, { type: 'audio/mp3' });
}
